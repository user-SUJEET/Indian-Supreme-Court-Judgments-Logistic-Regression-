# -*- coding: utf-8 -*-
"""Indian Supreme Court Judgments Logistic Regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LOYiZxfkAWdMYQxSya6RyqtLQGE9AMGN
"""

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

df=pd.read_csv("/content/sample_data/judgments.csv")

df.info()

df.info()

df.isnull().sum()

df.duplicated().sum()

df.describe().T

from matplotlib import pyplot as plt
import seaborn as sns
_df_0.groupby('count').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

df.shape

df.head()

df.columns





plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='Judgement_type')
plt.title('Distribution of Judgement Types')
plt.xlabel('Judgement Type')
plt.ylabel('Count')
plt.show()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df



df

df.isnull().sum()

# Fill missing values in 'language' column with the mode
df['pet'].fillna(df['pet'].mode()[0], inplace=True)

# Verify the changes
print(df['pet'].isnull().sum())

df

df.isnull().sum()

# Fill missing values in 'language' column with the mode
df['res','pet_adv','res_adv','bench','judgement_by'].fillna(df['res','pet_adv','res_adv','bench','judgement_by'].mode()[0], inplace=True)

# Verify the changes
print(df['res','pet_adv','res_adv','bench','judgement_by'].isnull().sum())

df.isnull().sum()

df

df.isnull().sum()



"""Outlier detection is typically performed on numerical data. Since the current dataset contains only categorical columns, standard numerical outlier detection methods cannot be applied."""

from sklearn.model_selection import train_test_split



df.columns



df.columns

X=df.drop('Judgement_type',axis=1)
y=df['Judgement_type']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

from sklearn.preprocessing import StandardScaler

X_train.shape

X_test.shape

X.shape

y_train.shape

y.shape

from sklearn.linear_model import LogisticRegression

lo=LogisticRegression()

lo

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Identify categorical columns (excluding the target variable 'Judgement_type' and 'pet' which was dropped)
categorical_features = X_train.select_dtypes(include=['object']).columns

# Create a ColumnTransformer to apply OneHotEncoder to categorical features
# 'passthrough' is used for columns that are not categorical
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough' # This will keep any non-categorical columns as they are
)

# Create a pipeline that first preprocesses the data and then applies Logistic Regression
model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', LogisticRegression(max_iter=1000))]) # Increased max_iter

# Fit the pipeline on the training data
model_pipeline.fit(X_train, y_train)

# You can now use the fitted pipeline to make predictions
# predictions = model_pipeline.predict(X_test)

# Use the fitted pipeline to get the score
model_pipeline.score(X_train, y_train)*100

